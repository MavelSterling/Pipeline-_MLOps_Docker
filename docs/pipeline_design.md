# Dise√±o del Pipeline de MLOps para Diagn√≥stico M√©dico

## üéØ Descripci√≥n

Este documento describe el dise√±o de un pipeline de MLOps completo para el diagn√≥stico m√©dico, capaz de manejar tanto enfermedades comunes (con abundantes datos) como enfermedades hu√©rfanas (con datos limitados). 

---

## üìä Diagrama del Pipeline

```mermaid
graph TB
    A[Ingesta de Datos] --> B[Validaci√≥n y Limpieza]
    B --> C[An√°lisis Exploratorio]
    C --> D[Preparaci√≥n de Datos]
    D --> E[Divisi√≥n Train/Validation/Test]
    E --> F[Entrenamiento de Modelos]
    F --> G[Validaci√≥n Cruzada]
    G --> H[Evaluaci√≥n de Modelos]
    H --> I[Selecci√≥n del Mejor Modelo]
    I --> J[Registro del Modelo]
    J --> K[Despliegue en Producci√≥n]
    K --> L[Monitoreo en Tiempo Real]
    L --> M[Retroalimentaci√≥n]
    M --> N[Re-entrenamiento]
    N --> F
  
    subgraph "Fuentes de Datos"
        O[EHR - Historias Cl√≠nicas]
        P[Laboratorios]
        Q[S√≠ntomas Reportados]
        R[Im√°genes M√©dicas]
    end
  
    O --> A
    P --> A
    Q --> A
    R --> A
  
    subgraph "Modelos Especializados"
        S[Modelo Enfermedades Comunes]
        T[Modelo Enfermedades Hu√©rfanas]
        U[Modelo Ensemble]
    end
  
    F --> S
    F --> T
    S --> U
    T --> U
    U --> I
```

---

## Dise√±o y an√°lisis

El sistema propuesto es una plataforma de apoyo diagn√≥stico que recibe s√≠ntomas del paciente, estima la posible condici√≥n cl√≠nica y clasifica la severidad del caso. Desde el dise√±o inicial existen restricciones importantes. La primera es la privacidad, porque se trabaja con informaci√≥n m√©dica sensible. Eso significa que los datos del paciente no pueden circular libremente ni almacenarse de forma insegura. El pipeline debe considerar controles de acceso, trazabilidad de qui√©n vio qu√© dato y protecci√≥n tanto en tr√°nsito como en reposo. La segunda restricci√≥n es la latencia. El sistema no se usa de forma offline, sino durante la evaluaci√≥n cl√≠nica. Por lo tanto, la respuesta tiene que ser pr√°cticamente inmediata para que tenga valor, especialmente cuando los s√≠ntomas apuntan a algo potencialmente serio como dolor de pecho intenso o dificultad para respirar. La tercera restricci√≥n es interpretabilidad. Un modelo en salud no puede limitarse a responder ‚Äúusted est√° enfermo de gravedad‚Äù sin m√°s. El sistema tiene que ser capaz de explicar qu√© combinaci√≥n de s√≠ntomas lo llev√≥ a esa conclusi√≥n, porque un profesional humano va a usar la salida como apoyo y necesita poder entenderla, validarla y, si es necesario, discutirla con el paciente. Finalmente, el dise√±o tiene que reconocer que no todos los problemas m√©dicos se comportan igual desde el punto de vista de datos. Hay condiciones comunes con muchos ejemplos disponibles y otras raras donde hay muy pocos datos. Eso obliga a estructurar el pipeline para que soporte ambos escenarios en lugar de asumir un √∫nico modelo universal.

En cuanto al tipo de informaci√≥n que debe procesar el sistema, hay varias clases de datos relevantes. Est√°n los datos estructurados, como fiebre medida en grados, nivel de dolor reportado en una escala num√©rica o presencia e intensidad de s√≠ntomas espec√≠ficos como tos, dolor abdominal o dificultad respiratoria. Esos datos son f√°ciles de usar directamente en los modelos porque tienen formato consistente. Existen tambi√©n datos derivados de notas m√©dicas o descripciones del paciente, que son texto libre. Ese tipo de informaci√≥n es menos uniforme y puede requerir procesar lenguaje natural para extraer se√±ales √∫tiles. Adem√°s, parte de la informaci√≥n cl√≠nica es temporal. No basta con saber ‚Äúhay dolor en el pecho‚Äù, importa desde cu√°ndo, si apareci√≥ de golpe o si est√° presente desde hace semanas, y si ha empeorado con el tiempo. Esa evoluci√≥n en el tiempo tambi√©n es parte del cuadro cl√≠nico y el pipeline debe estar preparado para integrarla cuando est√© disponible. El dise√±o general deja abierta la posibilidad de incorporar m√°s adelante modalidades extra como im√°genes m√©dicas o reportes de laboratorio, pero incluso en su forma b√°sica ya tiene que tratar con datos heterog√©neos que no vienen todos con el mismo formato ni la misma calidad.

## Desarrollo del modelo y manejo de datos

El pipeline de desarrollo comienza con la ingesta y la limpieza de datos cl√≠nicos. En un entorno real esa informaci√≥n llega de varias fuentes: registros cl√≠nicos electr√≥nicos del hospital, reportes de laboratorio, auto reporte del paciente y eventualmente dispositivos m√©dicos. Eso normalmente viene con formatos distintos, escalas diferentes y hasta maneras distintas de describir el mismo s√≠ntoma. Por ejemplo, un paciente puede decir ‚Äúme cuesta respirar‚Äù mientras que en otro registro aparece como ‚Äúdisnea moderada‚Äù. Antes de entrenar cualquier modelo es obligatorio normalizar todo eso en una representaci√≥n com√∫n. Este paso no es cosm√©tico, ya que un error en la estandarizaci√≥n puede ense√±ar al modelo una correlaci√≥n equivocada y eso despu√©s se traduce en malas decisiones cl√≠nicas.

Despu√©s de la limpieza se hace la separaci√≥n cl√°sica en entrenamiento, validaci√≥n y prueba, con el objetivo de poder medir generalizaci√≥n y no solo memoria. Aqu√≠ aparece una decisi√≥n importante: el sistema no se plantea como un √∫nico modelo monol√≠tico que lo predice todo. En su lugar, se asume que existen al menos dos familias de modelos. Por un lado, hay modelos entrenados con datos de condiciones comunes y frecuentes, como cuadros respiratorios t√≠picos o problemas digestivos leves. Para estos casos se pueden usar clasificadores supervisados est√°ndar, modelos en conjunto como gradient boosting o redes neuronales relativamente simples, porque hay suficientes ejemplos hist√≥ricos para aprender patrones estables. Por otro lado, hay un bloque diferente enfocado en condiciones menos frecuentes o m√°s cr√≠ticas, como eventos cardiacos agudos o cuadros neurol√≥gicos serios. En esos casos no siempre hay miles de ejemplos disponibles, as√≠ que se recurre a estrategias que funcionan con pocos datos, como transferencia de aprendizaje desde modelos ya entrenados en dominios parecidos o enfoques que priorizan la presencia combinada de s√≠ntomas clave en lugar de depender solo del volumen estad√≠stico.

Entre esas dos familias de modelos se inserta una l√≥gica de decisi√≥n que act√∫a como orquestador. Su trabajo no es promediar ciegamente, sino priorizar riesgo cl√≠nico. Si un modelo ‚Äúleve‚Äù dice que esto parece una infecci√≥n respiratoria no complicada, pero el modelo especializado en riesgo cardiopulmonar est√° disparando se√±ales fuertes porque hay dolor tor√°cico severo con dificultad respiratoria alta, el sistema no debe quedarse con el diagn√≥stico tranquilizador. Debe elevar la gravedad, porque desde el punto de vista cl√≠nico el peor caso manda. Ese componente de agregaci√≥n es parte esencial del pipeline porque lo acerca m√°s a c√≥mo piensa un m√©dico: cuando hay se√±ales de algo potencialmente grave, se trata como grave hasta demostrar lo contrario.

La validaci√≥n del sistema no se puede limitar a medir accuracy global. En salud importa mucho m√°s qu√© tan bien detecta los casos que realmente requieren atenci√≥n urgente y qu√© tanto evita alarmar sin motivo. Por eso se eval√∫an m√©tricas que capturan ambas cosas. Sensibilidad alta significa que el sistema casi no deja pasar casos peligrosos etiquet√°ndolos como leves. Especificidad razonable significa que no marca como ‚Äúgrave‚Äù a todo el mundo innecesariamente. Adem√°s se eval√∫a el comportamiento del modelo en distintos perfiles de paciente, porque un sistema cl√≠nico no puede funcionar bien solo en un subgrupo y mal en otro sin que eso se note. Finalmente, hay una capa expl√≠cita de validaci√≥n humana. Antes de considerar que una versi√≥n del modelo est√° lista para uso cl√≠nico, profesionales m√©dicos revisan ejemplos reales y determinan si las salidas del sistema tienen sentido cl√≠nico. Eso incluye revisar si la explicaci√≥n que da el modelo es coherente, si la clasificaci√≥n de severidad es prudente y si las recomendaciones son aceptables desde la pr√°ctica m√©dica.

## Producci√≥n, monitoreo y mejora continua

Una vez que el modelo supera la validaci√≥n t√©cnica y cl√≠nica, se despliega como un servicio. La forma pr√°ctica de hacerlo es empacar el modelo con su l√≥gica de preprocesamiento y exponerlo mediante una API en un contenedor. Ese contenedor se puede orquestar igual que cualquier otro microservicio, lo que facilita escalar horizontalmente si aumenta el n√∫mero de consultas. Este enfoque le da al hospital o a la instituci√≥n un punto claro de integraci√≥n: el sistema cl√≠nico le env√≠a los s√≠ntomas estructurados del paciente y recibe de vuelta una clasificaci√≥n de severidad y, cuando corresponde, una posible condici√≥n m√°s probable. El despliegue en contenedores tambi√©n facilita versionar y auditar. Se puede saber exactamente qu√© versi√≥n del modelo est√° corriendo, con qu√© pesos fue entrenado y con qu√© datos fue validado. Eso es fundamental en salud, porque en caso de auditor√≠a se tiene que poder responder por qu√© se dio cierta recomendaci√≥n en una fecha espec√≠fica.

Cuando el sistema est√° en producci√≥n no basta con que est√© disponible. Tiene que ser vigilado activamente. Por un lado se monitorean m√©tricas puramente t√©cnicas, como latencia, disponibilidad y tasa de error de la API. El sistema tiene que responder r√°pido y de forma estable porque se est√° usando en el flujo de trabajo cl√≠nico. Por otro lado se monitorean m√©tricas cl√≠nicas, como la distribuci√≥n de severidades que el sistema est√° emitiendo en el tiempo. Si de repente empieza a clasificar a casi todos los pacientes como casos graves, o al contrario deja de marcar casos agudos por completo, eso es se√±al de que algo cambi√≥ en los datos de entrada o en el contexto cl√≠nico. Ese fen√≥meno se conoce como drift y es inevitable en salud, porque la realidad cl√≠nica cambia. Aparecen nuevas variantes de virus, cambian los perfiles de paciente que consultan, cambian las gu√≠as m√©dicas. El pipeline no puede asumir que el modelo de hoy sirve igual dentro de seis meses. Tiene que detectar ese desajuste y registrarlo.

Ese monitoreo continuo alimenta la √∫ltima fase del pipeline, que es la mejora iterativa del modelo. Cada cierto tiempo, o cuando se detecta degradaci√≥n en el rendimiento cl√≠nico, se recolectan nuevos ejemplos reales, se vuelven a limpiar y normalizar, y se utilizan para reentrenar o ajustar el modelo. Ese reentrenamiento nunca se hace a ciegas. Antes de reemplazar el modelo en producci√≥n se compara la versi√≥n actual con la versi√≥n nueva en paralelo, usando datos reales recientes. Eso permite ver si el nuevo modelo realmente mejora o si introduce errores peligrosos. Solo cuando el nuevo modelo demuestra ser al menos tan seguro como el anterior y adem√°s ofrece una mejora real, se promueve a producci√≥n. Toda esta rotaci√≥n debe quedar registrada de manera formal, incluyendo qu√© versi√≥n estaba activa, cu√°ndo se cambi√≥ y por qu√© se cambi√≥. 

## Conclusi√≥n

El pipeline cubre el ciclo completo. Parte desde la ingesta cruda y desordenada de datos cl√≠nicos, pasa por limpieza y normalizaci√≥n, entrena modelos adecuados tanto para condiciones comunes como para las menos frecuentes, combina las se√±ales priorizando el riesgo m√°s alto, valida t√©cnica y cl√≠nicamente, despliega como servicio reproducible, monitorea el desempe√±o en tiempo real y se alimenta de vuelta para mejorar. 
